{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatDeepSeek } from \"@langchain/deepseek\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const model = new ChatDeepSeek(\n",
    "  {\n",
    "    model: \"deepseek-chat\",\n",
    "  },\n",
    ");\n",
    "\n",
    "await model.invoke([\n",
    "  new HumanMessage(\"讲个笑话\"),\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// StringOutputParser 提取api返回的文本数据\n",
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const parser = new StringOutputParser();\n",
    "\n",
    "const chain = model.pipe(parser);\n",
    "\n",
    "await chain.invoke([\n",
    "  new HumanMessage(\"讲个笑话\"),\n",
    "]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 部分 Parser 会内置一些预先设计好的 prompt 对模型进行引导\n",
    "import { StructuredOutputParser } from \"langchain/output_parsers\";\n",
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const parser = StructuredOutputParser.fromNamesAndDescriptions({\n",
    "  answer: \"用户问题的答案\",\n",
    "  evidence: \"你回答用户问题所依据的答案\",\n",
    "  confidence: \"问题答案的可信度评分，格式是百分数\",\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(parser.getFormatInstructions());\n",
    "// 先告诉 LLM 输出的类型\n",
    "// 然后，使用 few-shot （一种 prompt 技巧），也就是用示例告诉 LLM 什么是 JSON Schema，什么情况会被解析成功，什么情况不会被解析成功\n",
    "// 然后，再次强调类型的重要性，输出必须遵循给定的JSON Schema实例，确保所有字段严格匹配Schema中的定义，没有额外的属性，也没有遗漏的必需属性。\n",
    "// 并强调需要注意细节，比如不要在JSON对象中添加多余的逗号，这可能会导致解析失败。\n",
    "// 这些 prompt 质量非常高，把在该任务中大模型容易出现的问题都进行了强调，可以有效的保证输出的质量。\n",
    "// 最后才是给出，我们指定的 JSON 格式和对应的描述"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const prompt = PromptTemplate.fromTemplate(\n",
    "  \"尽可能的回答用的问题 \\n{instructions} \\n{question}\",\n",
    ");\n",
    "// const model = new ChatDeekSeek();\n",
    "\n",
    "const chain = prompt.pipe(model).pipe(parser);\n",
    "const res = await chain.invoke({\n",
    "  question: \"蒙娜丽莎的作者是谁？是什么时候绘制的\",\n",
    "  instructions: parser.getFormatInstructions(),\n",
    "});\n",
    "\n",
    "console.log(res);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// List Output Parser,限制列表格式得到指令\n",
    "import { CommaSeparatedListOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const parser = new CommaSeparatedListOutputParser();\n",
    "\n",
    "console.log(parser.getFormatInstructions());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// const model = new ChatOpenAI();\n",
    "const prompt = PromptTemplate.fromTemplate(\n",
    "  \"列出3个 {country} 的著名的互联网公司.\\n{instructions}\",\n",
    ");\n",
    "\n",
    "const chain = prompt.pipe(model).pipe(parser);\n",
    "\n",
    "const response = await chain.invoke({\n",
    "  country: \"America\",\n",
    "  instructions: parser.getFormatInstructions(),\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Auto Fix Parser ，对于部分对输出质量要求更高的场景，如果出现了输出不符合要求的情况，我们希望的不是让 LLM 反复输出（可能每次都是错的），因为 LLM 并没有意识到自己的错误。所以我们需要把报错的信息返回给 LLM，让他理解错在哪里，应该怎么修改。\n",
    "\n",
    "import { z } from \"zod\";\n",
    "const schema = z.object({\n",
    "  answer: z.string().describe(\"用户问题的答案\"),\n",
    "  confidence: z.number().min(0).max(100).describe(\n",
    "    \"问题答案的可信度评分，满分 100\",\n",
    "  ),\n",
    "});\n",
    "const parser = StructuredOutputParser.fromZodSchema(schema);\n",
    "const prompt = PromptTemplate.fromTemplate(\n",
    "  \"尽可能的回答用的问题 \\n{instructions} \\n{question}\",\n",
    ");\n",
    "// const model = new ChatOpenAI();\n",
    "\n",
    "const chain = prompt.pipe(model).pipe(parser);\n",
    "const res = await chain.invoke({\n",
    "  question: \"蒙娜丽莎的作者是谁？是什么时候绘制的\",\n",
    "  instructions: parser.getFormatInstructions(),\n",
    "});\n",
    "\n",
    "console.log(res);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// fixParse只是一个纯粹的json更合适处理，可以修复json格式的问题。\n",
    "import { OutputFixingParser } from \"langchain/output_parsers\";\n",
    "// 我们构造一个错误的输出，\n",
    "const wrongOutput = {\n",
    "  \"answer\":\n",
    "    \"蒙娜丽莎的作者是达芬奇，大约在16世纪初期（1503年至1506年之间）开始绘制。\",\n",
    "  \"sources\": \"90%\",\n",
    "};\n",
    "console.log({ OutputFixingParser });\n",
    "\n",
    "const fixParser = OutputFixingParser.fromLLM(model, parser);\n",
    "const output = await fixParser.parse(JSON.stringify(wrongOutput));\n",
    "output;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "出于节约成本考虑，可以实现gpt4的错误输出，用3.5来修复，可以节约成本"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
