{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 这是不支持LCEL的，所以定制会比较麻烦。但是可以方便地实现记忆对话。\n",
    "import { deepSeekChatModel } from \"./models/index.ts\";\n",
    "import { BufferMemory } from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "\n",
    "const memory = new BufferMemory();\n",
    "const chain = new ConversationChain({ llm: deepSeekChatModel, memory: memory });\n",
    "const res1 = await chain.call({ input: \"我是小明\" });\n",
    "res1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const res2 = await chain.call({ input: \"我叫什么？\" });\n",
    "res2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "内置Memory的机制\\\n",
    "首先是 BufferWindowMemory："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "// 导入BufferWindowMemory\n",
    "// 这里非常好理解，就是对聊天记录加了一个滑动窗口，只会记忆 k 个对话\n",
    "// 可以节省token\n",
    "import { BufferWindowMemory } from \"@langchain/core/memory\";\n",
    "const memory = new BufferWindowMemory({ k: 1 });\n",
    "const chain = new ConversationChain({ llm: model, memory: memory });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationSummaryMemory,官网提供的，随着聊天不断生成聊天记录摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ConversationSummaryMemory } from \"langchain/memory\";\n",
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { ChatDeepSeek } from \"@langchain/deepseek\";\n",
    "const memory = new ConversationSummaryMemory({\n",
    "  memoryKey: \"summary\",\n",
    "  llm: new ChatDeepSeek({\n",
    "    model: \"deepseek-chat\",\n",
    "    verbose: true,\n",
    "  }),\n",
    "});\n",
    "\n",
    "const model = deepSeekChatModel;\n",
    "const prompt = PromptTemplate.fromTemplate(`\n",
    "你是一个乐于助人的助手。尽你所能回答所有问题。\n",
    "\n",
    "这是聊天记录的摘要:\n",
    "{summary}\n",
    "Human: {input}\n",
    "AI:`);\n",
    "const chain = new ConversationChain({\n",
    "  llm: model,\n",
    "  prompt,\n",
    "  memory,\n",
    "  verbose: true,\n",
    "});\n",
    "\n",
    "const res1 = await chain.call({ input: \"我是小明\" });\n",
    "const res2 = await chain.call({ input: \"我叫什么？\" });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将 BufferWindowMemory 和 ConversationSummaryMemory 结合起来，根据 token\n",
    "数量，如果上下文历史过大时就切换到\n",
    "summary，如果上下文比较小时就使用原始的聊天记录，也就成了\n",
    "ConversationSummaryBufferMemory。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ConversationSummaryBufferMemory } from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "import { ChatDeepSeek } from \"@langchain/deepseek\";\n",
    "\n",
    "// 目前不支持deepseek模型的token数计算\n",
    "const model = deepSeekChatModel;\n",
    "const memory = new ConversationSummaryBufferMemory({\n",
    "  llm: new ChatDeepSeek({\n",
    "    model: \"deepseek-chat\",\n",
    "    verbose: true,\n",
    "  }),\n",
    "  maxTokenLimit: 200,\n",
    "});\n",
    "const chain = new ConversationChain({\n",
    "  llm: model,\n",
    "  memory: memory,\n",
    "  verbose: true,\n",
    "});\n",
    "const res1 = await chain.call({ input: \"我是小明\" });\n",
    "console.log({ res1 });\n",
    "const res2 = await chain.call({ input: \"我叫什么？\" });\n",
    "console.log({ res2 });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EntityMemory\n",
    "\n",
    "在人类聊天的过程中，我们实际在建立的是对各种实体（Entity）的记忆，例如两个刚认识的人，我们聊职业、聊公司、聊餐馆，我们记忆中存储方式可能是根据实体进行分类存储，这个人是什么职业、年龄；这个公司是什么情况；餐馆是什么环境和味道。EntityMemory\n",
    "希望模拟的就是在聊天中去生成和更新不同的实体的描述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import {\n",
    "  ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "  EntityMemory,\n",
    "} from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "\n",
    "const model = deepSeekChatModel;\n",
    "const memory = new EntityMemory({\n",
    "  llm: new ChatDeepSeek({\n",
    "    model: \"deepseek-chat\",\n",
    "    verbose: true,\n",
    "  }),\n",
    "  chatHistoryKey: \"history\",\n",
    "  entitiesKey: \"entities\",\n",
    "});\n",
    "const chain = new ConversationChain({\n",
    "  llm: model,\n",
    "  prompt: ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "  memory: memory,\n",
    "  verbose: true,\n",
    "});\n",
    "\n",
    "const res1 = await chain.call({ input: \"我是小明\" });\n",
    "console.log({ res1 });\n",
    "const res2 = await chain.call({ input: \"我叫什么？\" });\n",
    "console.log({ res2 });"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
