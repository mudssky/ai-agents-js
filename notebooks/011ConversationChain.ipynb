{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  response: \u001b[32m\"你好，小明！很高兴认识你。你今天过得怎么样？有什么我可以帮忙的吗？无论是学习、工作还是生活中的问题，我都很乐意为你提供帮助。😊\"\u001b[39m\n",
       "}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 这是不支持LCEL的，所以定制会比较麻烦。但是可以方便地实现记忆对话。\n",
    "import {deepSeekChatModel} from './models/index.ts'\n",
    "import { BufferMemory } from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "\n",
    "const memory = new BufferMemory();\n",
    "const chain = new ConversationChain({ llm: deepSeekChatModel, memory: memory });\n",
    "const res1 = await chain.call({ input: \"我是小明\" });\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{ response: \u001b[32m\"你刚才告诉我你叫小明呀！😊 如果你有其他名字或者昵称，也可以告诉我哦！\"\u001b[39m }"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const res2 = await chain.call({ input: \"我叫什么？\" });\n",
    "res2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "内置Memory的机制  \n",
    "首先是 BufferWindowMemory：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "BufferWindowMemory is not a constructor",
     "output_type": "error",
     "traceback": [
      "Stack trace:",
      "TypeError: BufferWindowMemory is not a constructor",
      "    at <anonymous>:5:16",
      "    at eventLoopTick (ext:core/01_core.js:177:7)"
     ]
    }
   ],
   "source": [
    "// 导入BufferWindowMemory\n",
    "// 这里非常好理解，就是对聊天记录加了一个滑动窗口，只会记忆 k 个对话\n",
    "// 可以节省token\n",
    "import { BufferWindowMemory } from \"@langchain/core/memory\";\n",
    "const memory = new BufferWindowMemory({ k: 1 });\n",
    "const chain = new ConversationChain({ llm: model, memory: memory });"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ConversationSummaryMemory,官网提供的，随着聊天不断生成聊天记录摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ConversationSummaryMemory } from \"langchain/memory\";\n",
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { ChatDeepSeek } from \"@langchain/deepseek\";\n",
    "const memory = new ConversationSummaryMemory({\n",
    "    memoryKey: \"summary\",\n",
    "    llm: new ChatDeepSeek({\n",
    "        model: \"deepseek-chat\", \n",
    "        verbose: true,\n",
    "    }),\n",
    "  });\n",
    "\n",
    "const model = deepSeekChatModel;\n",
    "const prompt = PromptTemplate.fromTemplate(`\n",
    "你是一个乐于助人的助手。尽你所能回答所有问题。\n",
    "\n",
    "这是聊天记录的摘要:\n",
    "{summary}\n",
    "Human: {input}\n",
    "AI:`);\n",
    "const chain = new ConversationChain({ llm: model, prompt, memory, verbose: true });\n",
    "\n",
    "const res1 = await chain.call({ input: \"我是小明\" });\n",
    "const res2 = await chain.call({ input: \"我叫什么？\" });\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将 BufferWindowMemory 和 ConversationSummaryMemory 结合起来，根据 token 数量，如果上下文历史过大时就切换到 summary，如果上下文比较小时就使用原始的聊天记录，也就成了 ConversationSummaryBufferMemory。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"我是小明\",\n",
      "  \"history\": \"\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatDeepSeek\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\n\\nHuman: 我是小明\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatDeepSeek\u001b[22m\u001b[39m] [10.01s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"你好，小明！很高兴认识你。你今天过得怎么样？有什么我可以帮忙的吗？无论是学习、工作还是生活中的问题，我都很乐意为你提供帮助哦！😊\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"你好，小明！很高兴认识你。你今天过得怎么样？有什么我可以帮忙的吗？无论是学习、工作还是生活中的问题，我都很乐意为你提供帮助哦！😊\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"promptTokens\": 63,\n",
      "                \"completionTokens\": 35,\n",
      "                \"totalTokens\": 98\n",
      "              },\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"model_name\": \"deepseek-chat\",\n",
      "              \"usage\": {\n",
      "                \"prompt_tokens\": 63,\n",
      "                \"completion_tokens\": 35,\n",
      "                \"total_tokens\": 98,\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"cached_tokens\": 0\n",
      "                },\n",
      "                \"prompt_cache_hit_tokens\": 0,\n",
      "                \"prompt_cache_miss_tokens\": 63\n",
      "              },\n",
      "              \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
      "            },\n",
      "            \"id\": \"04e18cf6-52ee-4a32-a4d3-62658a5741b1\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"usage_metadata\": {\n",
      "              \"output_tokens\": 35,\n",
      "              \"input_tokens\": 63,\n",
      "              \"total_tokens\": 98,\n",
      "              \"input_token_details\": {\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {}\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 63,\n",
      "      \"completionTokens\": 35,\n",
      "      \"totalTokens\": 98\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to calculate number of tokens, falling back to approximate count Error: Unknown model\n",
      "    at getEncodingNameForModel (file:///C:/home/Projects/AI/ai-agents/node_modules/js-tiktoken/dist/chunk-Z5MDQTGX.js:247:13)\n",
      "    at encodingForModel (file:///C:/home/Projects/AI/ai-agents/node_modules/@langchain/core/dist/utils/tiktoken.js:19:24)\n",
      "    at ChatDeepSeek.getNumTokens (file:///C:/home/Projects/AI/ai-agents/node_modules/@langchain/core/dist/language_models/base.js:197:40)\n",
      "    at ConversationSummaryBufferMemory.prune (file:///C:/home/Projects/AI/ai-agents/node_modules/langchain/dist/memory/summary_buffer.js:114:47)\n",
      "    at eventLoopTick (ext:core/01_core.js:177:7)\n",
      "    at async ConversationSummaryBufferMemory.saveContext (file:///C:/home/Projects/AI/ai-agents/node_modules/langchain/dist/memory/summary_buffer.js:96:9)\n",
      "    at async ConversationChain.invoke (file:///C:/home/Projects/AI/ai-agents/node_modules/langchain/dist/chains/base.js:71:13)\n",
      "    at async <anonymous>:17:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [10.03s] Exiting Chain run with output: {\n",
      "  \"response\": \"你好，小明！很高兴认识你。你今天过得怎么样？有什么我可以帮忙的吗？无论是学习、工作还是生活中的问题，我都很乐意为你提供帮助哦！😊\"\n",
      "}\n",
      "{\n",
      "  res1: {\n",
      "    response: \"你好，小明！很高兴认识你。你今天过得怎么样？有什么我可以帮忙的吗？无论是学习、工作还是生活中的问题，我都很乐意为你提供帮助哦！😊\"\n",
      "  }\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"我叫什么？\",\n",
      "  \"history\": \"Human: 我是小明\\nAI: 你好，小明！很高兴认识你。你今天过得怎么样？有什么我可以帮忙的吗？无论是学习、工作还是生活中的问题，我都很乐意为你提供帮助哦！😊\"\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatDeepSeek\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"The following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\\n\\nCurrent conversation:\\nHuman: 我是小明\\nAI: 你好，小明！很高兴认识你。你今天过得怎么样？有什么我可以帮忙的吗？无论是学习、工作还是生活中的问题，我都很乐意为你提供帮助哦！😊\\nHuman: 我叫什么？\\nAI:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatDeepSeek\u001b[22m\u001b[39m] [10.85s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"你刚刚告诉我你叫小明呀！😊 如果你有其他名字或者昵称，也可以告诉我哦！\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"你刚刚告诉我你叫小明呀！😊 如果你有其他名字或者昵称，也可以告诉我哦！\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"promptTokens\": 108,\n",
      "                \"completionTokens\": 22,\n",
      "                \"totalTokens\": 130\n",
      "              },\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"model_name\": \"deepseek-chat\",\n",
      "              \"usage\": {\n",
      "                \"prompt_tokens\": 108,\n",
      "                \"completion_tokens\": 22,\n",
      "                \"total_tokens\": 130,\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"cached_tokens\": 64\n",
      "                },\n",
      "                \"prompt_cache_hit_tokens\": 64,\n",
      "                \"prompt_cache_miss_tokens\": 44\n",
      "              },\n",
      "              \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
      "            },\n",
      "            \"id\": \"b90e308c-a71d-44c8-897e-bc3430804681\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"usage_metadata\": {\n",
      "              \"output_tokens\": 22,\n",
      "              \"input_tokens\": 108,\n",
      "              \"total_tokens\": 130,\n",
      "              \"input_token_details\": {\n",
      "                \"cache_read\": 64\n",
      "              },\n",
      "              \"output_token_details\": {}\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 108,\n",
      "      \"completionTokens\": 22,\n",
      "      \"totalTokens\": 130\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to calculate number of tokens, falling back to approximate count Error: Unknown model\n",
      "    at getEncodingNameForModel (file:///C:/home/Projects/AI/ai-agents/node_modules/js-tiktoken/dist/chunk-Z5MDQTGX.js:247:13)\n",
      "    at encodingForModel (file:///C:/home/Projects/AI/ai-agents/node_modules/@langchain/core/dist/utils/tiktoken.js:19:24)\n",
      "    at ChatDeepSeek.getNumTokens (file:///C:/home/Projects/AI/ai-agents/node_modules/@langchain/core/dist/language_models/base.js:197:40)\n",
      "    at ConversationSummaryBufferMemory.prune (file:///C:/home/Projects/AI/ai-agents/node_modules/langchain/dist/memory/summary_buffer.js:114:47)\n",
      "    at eventLoopTick (ext:core/01_core.js:177:7)\n",
      "    at async ConversationSummaryBufferMemory.saveContext (file:///C:/home/Projects/AI/ai-agents/node_modules/langchain/dist/memory/summary_buffer.js:96:9)\n",
      "    at async ConversationChain.invoke (file:///C:/home/Projects/AI/ai-agents/node_modules/langchain/dist/chains/base.js:71:13)\n",
      "    at async <anonymous>:23:14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [10.85s] Exiting Chain run with output: {\n",
      "  \"response\": \"你刚刚告诉我你叫小明呀！😊 如果你有其他名字或者昵称，也可以告诉我哦！\"\n",
      "}\n",
      "{ res2: { response: \"你刚刚告诉我你叫小明呀！😊 如果你有其他名字或者昵称，也可以告诉我哦！\" } }\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import { ConversationSummaryBufferMemory } from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "import {ChatDeepSeek} from '@langchain/deepseek'\n",
    "\n",
    "// 目前不支持deepseek模型的token数计算\n",
    "const model = deepSeekChatModel;\n",
    "const memory = new ConversationSummaryBufferMemory({\n",
    "  llm: new ChatDeepSeek({\n",
    "        model: \"deepseek-chat\", \n",
    "        verbose: true,\n",
    "    }),\n",
    "  maxTokenLimit: 200\n",
    "});\n",
    "const chain = new ConversationChain({ llm: model, memory: memory, verbose: true });\n",
    "const res1 = await chain.call({ input: \"我是小明\" });\n",
    "console.log({res1});\n",
    "const res2 = await chain.call({ input: \"我叫什么？\" });\n",
    "console.log({res2});"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " EntityMemory\n",
    "\n",
    "在人类聊天的过程中，我们实际在建立的是对各种实体（Entity）的记忆，例如两个刚认识的人，我们聊职业、聊公司、聊餐馆，我们记忆中存储方式可能是根据实体进行分类存储，这个人是什么职业、年龄；这个公司是什么情况；餐馆是什么环境和味道。EntityMemory 希望模拟的就是在聊天中去生成和更新不同的实体的描述。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatDeepSeek\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \\\"What do you know about him\\\" where \\\"him\\\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: my name is Jacob. how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Jacob,Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I'm working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n\\nLast line of conversation (for extraction):\\nHuman: 我是小明\\n\\nOutput:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatDeepSeek\u001b[22m\u001b[39m] [7.76s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"小明\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"小明\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"promptTokens\": 409,\n",
      "                \"completionTokens\": 1,\n",
      "                \"totalTokens\": 410\n",
      "              },\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"model_name\": \"deepseek-chat\",\n",
      "              \"usage\": {\n",
      "                \"prompt_tokens\": 409,\n",
      "                \"completion_tokens\": 1,\n",
      "                \"total_tokens\": 410,\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"cached_tokens\": 0\n",
      "                },\n",
      "                \"prompt_cache_hit_tokens\": 0,\n",
      "                \"prompt_cache_miss_tokens\": 409\n",
      "              },\n",
      "              \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
      "            },\n",
      "            \"id\": \"52c3f79c-4fb3-40ad-8c98-7c8dda26048b\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"usage_metadata\": {\n",
      "              \"output_tokens\": 1,\n",
      "              \"input_tokens\": 409,\n",
      "              \"total_tokens\": 410,\n",
      "              \"input_token_details\": {\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {}\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 409,\n",
      "      \"completionTokens\": 1,\n",
      "      \"totalTokens\": 410\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"我是小明\",\n",
      "  \"history\": \"\",\n",
      "  \"entities\": {\n",
      "    \"小明\": \"No current information known.\"\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatDeepSeek\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n{\\\"小明\\\":\\\"No current information known.\\\"}\\n\\nCurrent conversation:\\n\\nLast line:\\nHuman: 我是小明\\nYou:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatDeepSeek\u001b[22m\u001b[39m] [9.58s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"你好，小明！很高兴认识你。有什么我可以帮忙的吗？无论是回答问题、提供建议，还是讨论某个话题，我都很乐意协助你。😊\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"你好，小明！很高兴认识你。有什么我可以帮忙的吗？无论是回答问题、提供建议，还是讨论某个话题，我都很乐意协助你。😊\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"promptTokens\": 274,\n",
      "                \"completionTokens\": 32,\n",
      "                \"totalTokens\": 306\n",
      "              },\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"model_name\": \"deepseek-chat\",\n",
      "              \"usage\": {\n",
      "                \"prompt_tokens\": 274,\n",
      "                \"completion_tokens\": 32,\n",
      "                \"total_tokens\": 306,\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"cached_tokens\": 0\n",
      "                },\n",
      "                \"prompt_cache_hit_tokens\": 0,\n",
      "                \"prompt_cache_miss_tokens\": 274\n",
      "              },\n",
      "              \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
      "            },\n",
      "            \"id\": \"f014ae94-b845-4f97-8a8c-267544603451\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"usage_metadata\": {\n",
      "              \"output_tokens\": 32,\n",
      "              \"input_tokens\": 274,\n",
      "              \"total_tokens\": 306,\n",
      "              \"input_token_details\": {\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {}\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 274,\n",
      "      \"completionTokens\": 32,\n",
      "      \"totalTokens\": 306\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatDeepSeek\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update and add to the summary of the provided entity in the \\\"Entity\\\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\\nThe update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\\n\\nIf there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), output the exact string \\\"UNCHANGED\\\" below.\\n\\nFull conversation history (for context):\\nHuman: 我是小明\\nAI: 你好，小明！很高兴认识你。有什么我可以帮忙的吗？无论是回答问题、提供建议，还是讨论某个话题，我都很乐意协助你。😊\\n\\nEntity to summarize:\\n小明\\n\\nExisting summary of 小明:\\nNo current information known.\\n\\nLast line of conversation:\\nHuman: 我是小明\\nUpdated summary (or the exact string \\\"UNCHANGED\\\" if there is no new information about 小明 above):\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatDeepSeek\u001b[22m\u001b[39m] [7.87s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"小明 is a person who introduced themselves as \\\"小明\\\" in the conversation.\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"小明 is a person who introduced themselves as \\\"小明\\\" in the conversation.\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"promptTokens\": 244,\n",
      "                \"completionTokens\": 15,\n",
      "                \"totalTokens\": 259\n",
      "              },\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"model_name\": \"deepseek-chat\",\n",
      "              \"usage\": {\n",
      "                \"prompt_tokens\": 244,\n",
      "                \"completion_tokens\": 15,\n",
      "                \"total_tokens\": 259,\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"cached_tokens\": 0\n",
      "                },\n",
      "                \"prompt_cache_hit_tokens\": 0,\n",
      "                \"prompt_cache_miss_tokens\": 244\n",
      "              },\n",
      "              \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
      "            },\n",
      "            \"id\": \"d5f509ce-29b9-47bd-ba6c-d9a6f5b9f74b\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"usage_metadata\": {\n",
      "              \"output_tokens\": 15,\n",
      "              \"input_tokens\": 244,\n",
      "              \"total_tokens\": 259,\n",
      "              \"input_token_details\": {\n",
      "                \"cache_read\": 0\n",
      "              },\n",
      "              \"output_token_details\": {}\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 244,\n",
      "      \"completionTokens\": 15,\n",
      "      \"totalTokens\": 259\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [17.45s] Exiting Chain run with output: {\n",
      "  \"response\": \"你好，小明！很高兴认识你。有什么我可以帮忙的吗？无论是回答问题、提供建议，还是讨论某个话题，我都很乐意协助你。😊\"\n",
      "}\n",
      "{\n",
      "  res1: {\n",
      "    response: \"你好，小明！很高兴认识你。有什么我可以帮忙的吗？无论是回答问题、提供建议，还是讨论某个话题，我都很乐意协助你。😊\"\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatDeepSeek\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \\\"What do you know about him\\\" where \\\"him\\\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: my name is Jacob. how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Jacob,Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how's it going today?\\nAI: \\\"It's going great! How about you?\\\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \\\"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\\\"\\nLast line:\\nPerson #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I'm working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\nHuman: 我是小明\\nAI: 你好，小明！很高兴认识你。有什么我可以帮忙的吗？无论是回答问题、提供建议，还是讨论某个话题，我都很乐意协助你。😊\\nLast line of conversation (for extraction):\\nHuman: 我叫什么？\\n\\nOutput:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatDeepSeek\u001b[22m\u001b[39m] [9.16s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"NONE  \\n\\nExplanation: The last line \\\"我叫什么？\\\" translates to \\\"What is my name?\\\" and does not contain any proper nouns. The name \\\"小明\\\" (Xiao Ming) was mentioned earlier but is not in the last line, so it is not included.\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"NONE  \\n\\nExplanation: The last line \\\"我叫什么？\\\" translates to \\\"What is my name?\\\" and does not contain any proper nouns. The name \\\"小明\\\" (Xiao Ming) was mentioned earlier but is not in the last line, so it is not included.\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"promptTokens\": 451,\n",
      "                \"completionTokens\": 56,\n",
      "                \"totalTokens\": 507\n",
      "              },\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"model_name\": \"deepseek-chat\",\n",
      "              \"usage\": {\n",
      "                \"prompt_tokens\": 451,\n",
      "                \"completion_tokens\": 56,\n",
      "                \"total_tokens\": 507,\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"cached_tokens\": 384\n",
      "                },\n",
      "                \"prompt_cache_hit_tokens\": 384,\n",
      "                \"prompt_cache_miss_tokens\": 67\n",
      "              },\n",
      "              \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
      "            },\n",
      "            \"id\": \"9802a5b1-3c14-401f-a4b1-e5ffee262830\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"usage_metadata\": {\n",
      "              \"output_tokens\": 56,\n",
      "              \"input_tokens\": 451,\n",
      "              \"total_tokens\": 507,\n",
      "              \"input_token_details\": {\n",
      "                \"cache_read\": 384\n",
      "              },\n",
      "              \"output_token_details\": {}\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 451,\n",
      "      \"completionTokens\": 56,\n",
      "      \"totalTokens\": 507\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[chain/start]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] Entering Chain run with input: {\n",
      "  \"input\": \"我叫什么？\",\n",
      "  \"history\": \"Human: 我是小明\\nAI: 你好，小明！很高兴认识你。有什么我可以帮忙的吗？无论是回答问题、提供建议，还是讨论某个话题，我都很乐意协助你。😊\",\n",
      "  \"entities\": {\n",
      "    \"NONE  \\n\\nExplanation: The last line \\\"我叫什么？\\\" translates to \\\"What is my name?\\\" and does not contain any proper nouns. The name \\\"小明\\\" (Xiao Ming) was mentioned earlier but is not in the last line\": \"No current information known.\",\n",
      "    \"so it is not included.\": \"No current information known.\"\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatDeepSeek\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an assistant to a human, powered by a large language model trained by OpenAI.\\n\\nYou are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\\n\\nYou are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\\n\\nOverall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\\n\\nContext:\\n{\\\"NONE  \\\\n\\\\nExplanation: The last line \\\\\\\"我叫什么？\\\\\\\" translates to \\\\\\\"What is my name?\\\\\\\" and does not contain any proper nouns. The name \\\\\\\"小明\\\\\\\" (Xiao Ming) was mentioned earlier but is not in the last line\\\":\\\"No current information known.\\\",\\\"so it is not included.\\\":\\\"No current information known.\\\"}\\n\\nCurrent conversation:\\nHuman: 我是小明\\nAI: 你好，小明！很高兴认识你。有什么我可以帮忙的吗？无论是回答问题、提供建议，还是讨论某个话题，我都很乐意协助你。😊\\nLast line:\\nHuman: 我叫什么？\\nYou:\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m1:chain:ConversationChain > \u001b[1m2:llm:ChatDeepSeek\u001b[22m\u001b[39m] [8.40s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"你叫小明！😊 有什么我可以继续帮你的吗？\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"你叫小明！😊 有什么我可以继续帮你的吗？\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"promptTokens\": 381,\n",
      "                \"completionTokens\": 14,\n",
      "                \"totalTokens\": 395\n",
      "              },\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"model_name\": \"deepseek-chat\",\n",
      "              \"usage\": {\n",
      "                \"prompt_tokens\": 381,\n",
      "                \"completion_tokens\": 14,\n",
      "                \"total_tokens\": 395,\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"cached_tokens\": 192\n",
      "                },\n",
      "                \"prompt_cache_hit_tokens\": 192,\n",
      "                \"prompt_cache_miss_tokens\": 189\n",
      "              },\n",
      "              \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
      "            },\n",
      "            \"id\": \"1d63be85-3231-49b1-ba47-f096a9a63005\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"usage_metadata\": {\n",
      "              \"output_tokens\": 14,\n",
      "              \"input_tokens\": 381,\n",
      "              \"total_tokens\": 395,\n",
      "              \"input_token_details\": {\n",
      "                \"cache_read\": 192\n",
      "              },\n",
      "              \"output_token_details\": {}\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 381,\n",
      "      \"completionTokens\": 14,\n",
      "      \"totalTokens\": 395\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatDeepSeek\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update and add to the summary of the provided entity in the \\\"Entity\\\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\\nThe update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\\n\\nIf there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), output the exact string \\\"UNCHANGED\\\" below.\\n\\nFull conversation history (for context):\\nHuman: 我是小明\\nAI: 你好，小明！很高兴认识你。有什么我可以帮忙的吗？无论是回答问题、提供建议，还是讨论某个话题，我都很乐意协助你。😊\\nHuman: 我叫什么？\\nAI: 你叫小明！😊 有什么我可以继续帮你的吗？\\n\\nEntity to summarize:\\nNONE  \\n\\nExplanation: The last line \\\"我叫什么？\\\" translates to \\\"What is my name?\\\" and does not contain any proper nouns. The name \\\"小明\\\" (Xiao Ming) was mentioned earlier but is not in the last line\\n\\nExisting summary of NONE  \\n\\nExplanation: The last line \\\"我叫什么？\\\" translates to \\\"What is my name?\\\" and does not contain any proper nouns. The name \\\"小明\\\" (Xiao Ming) was mentioned earlier but is not in the last line:\\nNo current information known.\\n\\nLast line of conversation:\\nHuman: 我叫什么？\\nUpdated summary (or the exact string \\\"UNCHANGED\\\" if there is no new information about NONE  \\n\\nExplanation: The last line \\\"我叫什么？\\\" translates to \\\"What is my name?\\\" and does not contain any proper nouns. The name \\\"小明\\\" (Xiao Ming) was mentioned earlier but is not in the last line above):\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatDeepSeek\u001b[22m\u001b[39m] [9.23s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"UNCHANGED  \\n\\nExplanation: The last line \\\"我叫什么？\\\" translates to \\\"What is my name?\\\" and does not contain any proper nouns. The name \\\"小明\\\" (Xiao Ming) was mentioned earlier but is not in the last line. Therefore, there is no new information to update the summary.\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"UNCHANGED  \\n\\nExplanation: The last line \\\"我叫什么？\\\" translates to \\\"What is my name?\\\" and does not contain any proper nouns. The name \\\"小明\\\" (Xiao Ming) was mentioned earlier but is not in the last line. Therefore, there is no new information to update the summary.\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"promptTokens\": 409,\n",
      "                \"completionTokens\": 64,\n",
      "                \"totalTokens\": 473\n",
      "              },\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"model_name\": \"deepseek-chat\",\n",
      "              \"usage\": {\n",
      "                \"prompt_tokens\": 409,\n",
      "                \"completion_tokens\": 64,\n",
      "                \"total_tokens\": 473,\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"cached_tokens\": 128\n",
      "                },\n",
      "                \"prompt_cache_hit_tokens\": 128,\n",
      "                \"prompt_cache_miss_tokens\": 281\n",
      "              },\n",
      "              \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
      "            },\n",
      "            \"id\": \"386c1ce3-99cd-4996-95f4-14cd7301f37a\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"usage_metadata\": {\n",
      "              \"output_tokens\": 64,\n",
      "              \"input_tokens\": 409,\n",
      "              \"total_tokens\": 473,\n",
      "              \"input_token_details\": {\n",
      "                \"cache_read\": 128\n",
      "              },\n",
      "              \"output_token_details\": {}\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 409,\n",
      "      \"completionTokens\": 64,\n",
      "      \"totalTokens\": 473\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[32m[llm/start]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatDeepSeek\u001b[22m\u001b[39m] Entering LLM run with input: {\n",
      "  \"messages\": [\n",
      "    [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain_core\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update and add to the summary of the provided entity in the \\\"Entity\\\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\\nThe update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\\n\\nIf there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), output the exact string \\\"UNCHANGED\\\" below.\\n\\nFull conversation history (for context):\\nHuman: 我是小明\\nAI: 你好，小明！很高兴认识你。有什么我可以帮忙的吗？无论是回答问题、提供建议，还是讨论某个话题，我都很乐意协助你。😊\\nHuman: 我叫什么？\\nAI: 你叫小明！😊 有什么我可以继续帮你的吗？\\n\\nEntity to summarize:\\nso it is not included.\\n\\nExisting summary of so it is not included.:\\nNo current information known.\\n\\nLast line of conversation:\\nHuman: 我叫什么？\\nUpdated summary (or the exact string \\\"UNCHANGED\\\" if there is no new information about so it is not included. above):\",\n",
      "          \"additional_kwargs\": {},\n",
      "          \"response_metadata\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ]\n",
      "}\n",
      "\u001b[36m[llm/end]\u001b[39m [\u001b[90m\u001b[1m1:llm:ChatDeepSeek\u001b[22m\u001b[39m] [13.92s] Exiting LLM run with output: {\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"UNCHANGED\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain_core\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"UNCHANGED\",\n",
      "            \"additional_kwargs\": {},\n",
      "            \"response_metadata\": {\n",
      "              \"tokenUsage\": {\n",
      "                \"promptTokens\": 279,\n",
      "                \"completionTokens\": 4,\n",
      "                \"totalTokens\": 283\n",
      "              },\n",
      "              \"finish_reason\": \"stop\",\n",
      "              \"model_name\": \"deepseek-chat\",\n",
      "              \"usage\": {\n",
      "                \"prompt_tokens\": 279,\n",
      "                \"completion_tokens\": 4,\n",
      "                \"total_tokens\": 283,\n",
      "                \"prompt_tokens_details\": {\n",
      "                  \"cached_tokens\": 192\n",
      "                },\n",
      "                \"prompt_cache_hit_tokens\": 192,\n",
      "                \"prompt_cache_miss_tokens\": 87\n",
      "              },\n",
      "              \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
      "            },\n",
      "            \"id\": \"e1fa243a-6fab-4ca7-8ce8-2fd62eb2496d\",\n",
      "            \"tool_calls\": [],\n",
      "            \"invalid_tool_calls\": [],\n",
      "            \"usage_metadata\": {\n",
      "              \"output_tokens\": 4,\n",
      "              \"input_tokens\": 279,\n",
      "              \"total_tokens\": 283,\n",
      "              \"input_token_details\": {\n",
      "                \"cache_read\": 192\n",
      "              },\n",
      "              \"output_token_details\": {}\n",
      "            }\n",
      "          }\n",
      "        },\n",
      "        \"generationInfo\": {\n",
      "          \"finish_reason\": \"stop\"\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llmOutput\": {\n",
      "    \"tokenUsage\": {\n",
      "      \"promptTokens\": 279,\n",
      "      \"completionTokens\": 4,\n",
      "      \"totalTokens\": 283\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\u001b[36m[chain/end]\u001b[39m [\u001b[90m\u001b[1m1:chain:ConversationChain\u001b[22m\u001b[39m] [31.55s] Exiting Chain run with output: {\n",
      "  \"response\": \"你叫小明！😊 有什么我可以继续帮你的吗？\"\n",
      "}\n",
      "{ res2: { response: \"你叫小明！😊 有什么我可以继续帮你的吗？\" } }\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import { EntityMemory, ENTITY_MEMORY_CONVERSATION_TEMPLATE } from \"langchain/memory\";\n",
    "import { ConversationChain } from \"langchain/chains\";\n",
    "\n",
    "const model = deepSeekChatModel;\n",
    "const memory = new EntityMemory({\n",
    "    llm: new ChatDeepSeek({\n",
    "        model: \"deepseek-chat\",\n",
    "        verbose: true \n",
    "    }),\n",
    "    chatHistoryKey: \"history\",\n",
    "    entitiesKey: \"entities\"\n",
    "});\n",
    "const chain = new ConversationChain({ \n",
    "    llm: model, \n",
    "    prompt: ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
    "    memory: memory, \n",
    "    verbose: true \n",
    "});\n",
    "\n",
    "const res1 = await chain.call({ input: \"我是小明\" });\n",
    "console.log({res1});\n",
    "const res2 = await chain.call({ input: \"我叫什么？\" });\n",
    "console.log({res2});"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
