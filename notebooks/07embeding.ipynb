{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { TextLoader } from \"langchain/document_loaders/fs/text\";\n",
    "import { RecursiveCharacterTextSplitter } from \"langchain/text_splitter\";\n",
    "const loader = new TextLoader(\"data/kong.txt\");\n",
    "const docs = await loader.load();\n",
    "\n",
    "const splitter = new RecursiveCharacterTextSplitter({\n",
    "    chunkSize: 100,\n",
    "    chunkOverlap: 20,\n",
    "  });\n",
    "\n",
    "const splitDocs = await splitter.splitDocuments(docs);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document {\n",
      "  pageContent: \"鲁镇的酒店的格局，是和别处不同的：都是当街一个曲尺形的大柜台，柜里面预备着热水，可以随时温酒。做工的人，傍午傍晚散了工，每每花四文铜钱，买一碗酒，——这是二十多年前的事，现在每碗要涨到十文，——靠柜\",\n",
      "  metadata: { source: \"data/kong.txt\", loc: { lines: { from: 2, to: 2 } } },\n",
      "  id: undefined\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "//deno-ignore-cell\n",
    "import { OpenAIEmbeddings } from \"@langchain/openai\";\n",
    "const embeddings = new OpenAIEmbeddings()\n",
    "console.log(splitDocs[0])\n",
    "// Document {\n",
    "//   pageContent: \"鲁镇的酒店的格局，是和别处不同的：都是当街一个曲尺形的大柜台，柜里面预备着热水，可以随时温酒。做工的人，傍午傍晚散了工，每每花四文铜钱，买一碗酒，——这是二十多年前的事，现在每碗要涨到十文，——靠柜外\",\n",
    "//   metadata: { source: \"data/kong.txt\", loc: { lines: { from: 1, to: 1 } } }\n",
    "// }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bge-large和bge-m3都是智谱开源的embeding模型  \n",
    "large是中文专用模型，适合纯中文场景，并且模型1.3B较大，资源消耗高  \n",
    "m3是多语言模型，资源消耗更低  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "    \u001b[33m0.008740378\u001b[39m,    \u001b[33m0.04719728\u001b[39m,  \u001b[33m-0.033101488\u001b[39m,   \u001b[33m0.026490076\u001b[39m, \u001b[33m-0.016458334\u001b[39m,\n",
       "   \u001b[33m-0.007930168\u001b[39m, \u001b[33m-0.0060368213\u001b[39m,   \u001b[33m0.038651697\u001b[39m,   \u001b[33m0.027293922\u001b[39m, \u001b[33m-0.029894743\u001b[39m,\n",
       "    \u001b[33m0.014001312\u001b[39m,   \u001b[33m0.013423827\u001b[39m,  \u001b[33m-0.049799044\u001b[39m, \u001b[33m-0.0127271665\u001b[39m,  \u001b[33m0.055749197\u001b[39m,\n",
       "   \u001b[33m0.0030935942\u001b[39m,   \u001b[33m0.029488508\u001b[39m,  \u001b[33m-0.009582613\u001b[39m, \u001b[33m0.00053053827\u001b[39m, \u001b[33m-0.038016077\u001b[39m,\n",
       "   \u001b[33m-0.008396971\u001b[39m,   \u001b[33m0.009748647\u001b[39m,  \u001b[33m-0.023752507\u001b[39m,   \u001b[33m0.056000393\u001b[39m, \u001b[33m0.0004296581\u001b[39m,\n",
       "   \u001b[33m0.0034583604\u001b[39m,  \u001b[33m-0.037966553\u001b[39m,   \u001b[33m0.028785648\u001b[39m,   \u001b[33m0.066896304\u001b[39m,  \u001b[33m0.036451742\u001b[39m,\n",
       "    \u001b[33m0.016272554\u001b[39m,  \u001b[33m-0.010934695\u001b[39m,   \u001b[33m0.026729824\u001b[39m,  \u001b[33m-0.014664751\u001b[39m,  \u001b[33m0.040016092\u001b[39m,\n",
       "   \u001b[33m-0.017349761\u001b[39m,  \u001b[33m-0.029412014\u001b[39m,  \u001b[33m-0.007202131\u001b[39m,  \u001b[33m-0.026093092\u001b[39m,    \u001b[33m0.0738953\u001b[39m,\n",
       "    \u001b[33m0.009295809\u001b[39m,   \u001b[33m0.001959285\u001b[39m,    \u001b[33m0.02944274\u001b[39m,   \u001b[33m0.020640664\u001b[39m, \u001b[33m-0.031330626\u001b[39m,\n",
       "    \u001b[33m-0.06177479\u001b[39m,  \u001b[33m-0.012812906\u001b[39m,  \u001b[33m-0.023647763\u001b[39m,   \u001b[33m-0.03839418\u001b[39m, \u001b[33m-0.008633445\u001b[39m,\n",
       "    \u001b[33m-0.02122242\u001b[39m,   \u001b[33m0.004130641\u001b[39m,   \u001b[33m0.044303004\u001b[39m,  \u001b[33m-0.024918107\u001b[39m, \u001b[33m-0.052432578\u001b[39m,\n",
       "    \u001b[33m0.029094325\u001b[39m, \u001b[33m-0.0005865712\u001b[39m,  \u001b[33m-0.004050862\u001b[39m,  \u001b[33m-0.046737757\u001b[39m,   \u001b[33m0.02026808\u001b[39m,\n",
       "    \u001b[33m-0.02235496\u001b[39m, \u001b[33m-0.0041085132\u001b[39m,    \u001b[33m0.01386025\u001b[39m,  \u001b[33m-0.007281756\u001b[39m, \u001b[33m0.0027739669\u001b[39m,\n",
       "    \u001b[33m0.062063575\u001b[39m,   \u001b[33m0.026642555\u001b[39m,   \u001b[33m0.050960347\u001b[39m,  \u001b[33m-0.026590403\u001b[39m,   \u001b[33m-0.0266551\u001b[39m,\n",
       "  \u001b[33m-0.0016769489\u001b[39m,   \u001b[33m0.043717537\u001b[39m,  \u001b[33m-0.018734777\u001b[39m,  \u001b[33m-0.017280508\u001b[39m,  \u001b[33m-0.01129639\u001b[39m,\n",
       "    \u001b[33m0.027472211\u001b[39m,  \u001b[33m-0.007818255\u001b[39m,   \u001b[33m0.018880531\u001b[39m,  \u001b[33m-0.014438486\u001b[39m,  \u001b[33m0.004413911\u001b[39m,\n",
       "    \u001b[33m0.041075245\u001b[39m,   \u001b[33m0.012397626\u001b[39m,   \u001b[33m0.032543804\u001b[39m,   \u001b[33m0.031242803\u001b[39m,  \u001b[33m-0.02366127\u001b[39m,\n",
       "   \u001b[33m-0.009380742\u001b[39m,   \u001b[33m0.016696243\u001b[39m, \u001b[33m-0.0013406677\u001b[39m,   \u001b[33m0.004778809\u001b[39m, \u001b[33m-0.056721617\u001b[39m,\n",
       "    \u001b[33m0.018335594\u001b[39m,  \u001b[33m0.0047367876\u001b[39m,  \u001b[33m-0.004377444\u001b[39m,  \u001b[33m-0.021177392\u001b[39m,  \u001b[33m0.014144245\u001b[39m,\n",
       "   \u001b[33m-0.024970781\u001b[39m,     \u001b[33m-0.036672\u001b[39m,  \u001b[33m0.0026365572\u001b[39m,    \u001b[33m0.05141933\u001b[39m, \u001b[33m0.0050144703\u001b[39m,\n",
       "  ... 924 more items\n",
       "]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { OllamaEmbeddings } from \"npm:@langchain/ollama\";\n",
    "const embeddings = new OllamaEmbeddings({\n",
    "  model: \"bge-m3\",\n",
    "  baseUrl: \"http://localhost:11434\", // Default value\n",
    "});\n",
    "const res =await embeddings.embedQuery(splitDocs[0].pageContent)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 创建 MemoryVectorStore\n",
    "\n",
    "这是在内存中构建的向量数据库  \n",
    "注意，因为 embedding 向量是需要有一定的花费的，所以仅在学习和测试时使用 MemoryVectorStore，而在真实项目中，搭建其他向量数据库，或者使用云数据库。  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { MemoryVectorStore } from \"langchain/vectorstores/memory\";\n",
    "\n",
    "const vectorstore = new MemoryVectorStore(embeddings);\n",
    "await vectorstore.addDocuments(splitDocs);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"你读过书么？”我略略点一点头。他说，“读过书，……我便考你一考。茴香豆的茴字，怎样写的？”我想，讨饭一样的人，也配考我么？便回过脸去，不再理会。孔乙己等了许久，很恳切的说道，“不能写罢？……我教给你，\"\u001b[39m,\n",
       "    metadata: { source: \u001b[32m\"data/kong.txt\"\u001b[39m, loc: { lines: { from: \u001b[33m8\u001b[39m, to: \u001b[33m8\u001b[39m } } },\n",
       "    id: \u001b[90mundefined\u001b[39m\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"很恳切的说道，“不能写罢？……我教给你，记着！这些字应该记着。将来做掌柜的时候，写账要用。”我暗想我和掌柜的等级还很远呢，而且我们掌柜也从不将茴香豆上账；又好笑，又不耐烦，懒懒的答他道，“谁要你教，不\"\u001b[39m,\n",
       "    metadata: { source: \u001b[32m\"data/kong.txt\"\u001b[39m, loc: { lines: { from: \u001b[33m8\u001b[39m, to: \u001b[33m8\u001b[39m } } },\n",
       "    id: \u001b[90mundefined\u001b[39m\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 创建一个 retriever，这也是可以直接从 vector store 的实例中自动生成，这里我们传入了参数 2，代表对应每个输入，我们想要返回相似度最高的两个文本内容\n",
    "const retriever = vectorstore.asRetriever(2)\n",
    "// 然后，我们就可以使用 retriever 来进行文档的提取\n",
    "await retriever.invoke(\"茴香豆是做什么用的\")\n",
    "// 可以看到结果提取出茴香豆相关的内容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"多年前的事，现在每碗要涨到十文，——靠柜外站着，热热的喝了休息；倘肯多花一文，便可以买一碟盐煮笋，或者茴香豆，做下酒物了，如果出到十几文，那就能买一样荤菜，但这些顾客，多是短衣帮⑴，大抵没有这样阔绰⑵\"\u001b[39m,\n",
       "    metadata: { source: \u001b[32m\"data/kong.txt\"\u001b[39m, loc: { lines: { from: \u001b[33m2\u001b[39m, to: \u001b[33m2\u001b[39m } } },\n",
       "    id: \u001b[90mundefined\u001b[39m\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"些顾客，多是短衣帮⑴，大抵没有这样阔绰⑵。只有穿长衫的，才踱进店面隔壁的房子里，要酒要菜，慢慢地坐喝。\"\u001b[39m,\n",
       "    metadata: { source: \u001b[32m\"data/kong.txt\"\u001b[39m, loc: { lines: { from: \u001b[33m2\u001b[39m, to: \u001b[33m2\u001b[39m } } },\n",
       "    id: \u001b[90mundefined\u001b[39m\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await retriever.invoke(\"下酒菜一般是什么？\")\n",
    "// 提取的时候，是根据相似度进行度量的，所以如果用户提问的特别简洁，并没有相应的关键词，就会出现提取的信息错误的问题，\n",
    "// 下面没有截取到孔乙己下酒物相关的（温两碗酒，要一碟茴香豆）分块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"孔乙己是这样的使人快活，可是没有他，别人也便这么过。\"\u001b[39m,\n",
       "    metadata: { source: \u001b[32m\"data/kong.txt\"\u001b[39m, loc: { lines: { from: \u001b[33m10\u001b[39m, to: \u001b[33m10\u001b[39m } } },\n",
       "    id: \u001b[90mundefined\u001b[39m\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"听人家背地里谈论，孔乙己原来也读过书，但终于没有进学⑼，又不会营生⑽；于是愈过愈穷，弄到将要讨饭了。幸而写得一笔好字，便替人家钞⑾钞书，换一碗饭吃。可惜他又有一样坏脾气，便是好喝懒做。坐不到几天，便\"\u001b[39m,\n",
       "    metadata: { source: \u001b[32m\"data/kong.txt\"\u001b[39m, loc: { lines: { from: \u001b[33m6\u001b[39m, to: \u001b[33m6\u001b[39m } } },\n",
       "    id: \u001b[90mundefined\u001b[39m\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 如果涉及多层语意的情况，也会有问题，有运气的成分，所以返回更多的数据源就会有价值\n",
    "await retriever.invoke(\"孔乙己用什么谋生？\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建本地vector store\n",
    "这里我们使用faiss，这是facebook开源的，node和python都可以使用\n",
    "\n",
    "也可以使用HNSWLib  \n",
    "\n",
    "另外faiss-node，使用pnpm直接安装，langchain里面会报导入错误。。。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
