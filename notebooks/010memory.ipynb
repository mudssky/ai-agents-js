{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  HumanMessage {\n",
       "    \"content\": \"hi\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    \"content\": \"What can I do for you?\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {},\n",
       "    \"tool_calls\": [],\n",
       "    \"invalid_tool_calls\": []\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatMessageHistory } from \"langchain/stores/message/in_memory\";\n",
    "import { HumanMessage, AIMessage } from \"@langchain/core/messages\";\n",
    "const history = new ChatMessageHistory();\n",
    "await history.addMessage(new HumanMessage(\"hi\"));\n",
    "await history.addMessage(new AIMessage(\"What can I do for you?\"));\n",
    "const messages = await history.getMessages();\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```typescript\n",
    "export abstract class BaseChatMessageHistory extends Serializable {\n",
    "  public abstract getMessages(): Promise<BaseMessage[]>;\n",
    "\n",
    "  public abstract addMessage(message: BaseMessage): Promise<void>;\n",
    "\n",
    "  public abstract addUserMessage(message: string): Promise<void>;\n",
    "\n",
    "  public abstract addAIChatMessage(message: string): Promise<void>;\n",
    "\n",
    "  public abstract clear(): Promise<void>;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  \"id\": \"850eb88b-83fd-4c00-a178-e0ad6d4d23be\",\n",
       "  \"content\": \"Hi Kai! It's great to meet you. How can I assist you today? Whether you have questions, need advice, or just want to chat, I'm here to help!\",\n",
       "  \"additional_kwargs\": {},\n",
       "  \"response_metadata\": {\n",
       "    \"tokenUsage\": {\n",
       "      \"promptTokens\": 63,\n",
       "      \"completionTokens\": 37,\n",
       "      \"totalTokens\": 100\n",
       "    },\n",
       "    \"finish_reason\": \"stop\",\n",
       "    \"model_name\": \"deepseek-chat\",\n",
       "    \"usage\": {\n",
       "      \"prompt_tokens\": 63,\n",
       "      \"completion_tokens\": 37,\n",
       "      \"total_tokens\": 100,\n",
       "      \"prompt_tokens_details\": {\n",
       "        \"cached_tokens\": 0\n",
       "      },\n",
       "      \"prompt_cache_hit_tokens\": 0,\n",
       "      \"prompt_cache_miss_tokens\": 63\n",
       "    },\n",
       "    \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
       "  },\n",
       "  \"tool_calls\": [],\n",
       "  \"invalid_tool_calls\": [],\n",
       "  \"usage_metadata\": {\n",
       "    \"output_tokens\": 37,\n",
       "    \"input_tokens\": 63,\n",
       "    \"total_tokens\": 100,\n",
       "    \"input_token_details\": {\n",
       "      \"cache_read\": 0\n",
       "    },\n",
       "    \"output_token_details\": {}\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// æ‰‹åŠ¨ç»´æŠ¤\n",
    "import { ChatPromptTemplate, MessagesPlaceholder } from \"@langchain/core/prompts\";\n",
    "import { ChatDeepSeek } from \"@langchain/deepseek\";\n",
    "\n",
    "const chatModel = new ChatDeepSeek({\n",
    "    model: \"deepseek-chat\",\n",
    "  });\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", `You are a helpful assistant. Answer all questions to the best of your ability.\n",
    "    You are talkative and provides lots of specific details from its context. \n",
    "    If the you does not know the answer to a question, it truthfully says you do not know.`],\n",
    "    new MessagesPlaceholder(\"history_message\"),\n",
    "]);\n",
    "\n",
    "const chain = prompt.pipe(chatModel);\n",
    "\n",
    "\n",
    "const history = new ChatMessageHistory();\n",
    "await history.addMessage(new HumanMessage(\"hi, my name is Kai\"));\n",
    "const res1 = await chain.invoke({\n",
    "    history_message: await history.getMessages()\n",
    "})\n",
    "res1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  \"id\": \"a9afee9a-b08d-464c-88e4-b0e29ed111bf\",\n",
       "  \"content\": \"Your name is Kai! You introduced yourself earlier by saying, \\\"Hi, my name is Kai.\\\" If there's anything specific you'd like to discuss or ask, feel free to let me know! ğŸ˜Š\",\n",
       "  \"additional_kwargs\": {},\n",
       "  \"response_metadata\": {\n",
       "    \"tokenUsage\": {\n",
       "      \"promptTokens\": 108,\n",
       "      \"completionTokens\": 42,\n",
       "      \"totalTokens\": 150\n",
       "    },\n",
       "    \"finish_reason\": \"stop\",\n",
       "    \"model_name\": \"deepseek-chat\",\n",
       "    \"usage\": {\n",
       "      \"prompt_tokens\": 108,\n",
       "      \"completion_tokens\": 42,\n",
       "      \"total_tokens\": 150,\n",
       "      \"prompt_tokens_details\": {\n",
       "        \"cached_tokens\": 64\n",
       "      },\n",
       "      \"prompt_cache_hit_tokens\": 64,\n",
       "      \"prompt_cache_miss_tokens\": 44\n",
       "    },\n",
       "    \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
       "  },\n",
       "  \"tool_calls\": [],\n",
       "  \"invalid_tool_calls\": [],\n",
       "  \"usage_metadata\": {\n",
       "    \"output_tokens\": 42,\n",
       "    \"input_tokens\": 108,\n",
       "    \"total_tokens\": 150,\n",
       "    \"input_token_details\": {\n",
       "      \"cache_read\": 64\n",
       "    },\n",
       "    \"output_token_details\": {}\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// è¿™é‡ŒæŠŠå¯¹è¯çš„ç»“æœä¹Ÿæ‰‹åŠ¨æ·»åŠ åˆ°å†å²è®°å½•ä¸­\n",
    "await history.addMessage(res1)\n",
    "await history.addMessage(new HumanMessage(\"What is my name?\"));\n",
    "const res2 = await chain.invoke({\n",
    "    history_message: await history.getMessages()\n",
    "})\n",
    "res2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunnableWithMessageHistory æœ‰å‡ ä¸ªå‚æ•°ï¼š\n",
    "- runnable å°±æ˜¯éœ€è¦è¢«åŒ…è£¹çš„ chainï¼Œå¯ä»¥æ˜¯ä»»æ„ chain\n",
    "- getMessageHistory æ¥æ”¶ä¸€ä¸ªå‡½æ•°ï¼Œå‡½æ•°éœ€è¦æ ¹æ®ä¼ å…¥çš„ _sessionIdï¼Œå»è·å–å¯¹åº”çš„ ChatMessageHistory å¯¹è±¡ï¼Œè¿™é‡Œæˆ‘ä»¬æ²¡æœ‰ session ç®¡ç†ï¼Œæ‰€ä»¥å°±è¿”å›é»˜è®¤çš„å¯¹è±¡\n",
    "- inputMessagesKey ç”¨æˆ·ä¼ å…¥çš„ä¿¡æ¯ key çš„åç§°ï¼Œå› ä¸º RunnableWithMessageHistory è¦è‡ªåŠ¨è®°å½•ç”¨æˆ·å’Œ llm å‘é€çš„ä¿¡æ¯ï¼Œæ‰€ä»¥éœ€è¦åœ¨è¿™é‡Œå£°æ˜ç”¨æˆ·ä»¥ä»€ä¹ˆ key ä¼ å…¥ä¿¡æ¯\n",
    "- historyMessagesKeyï¼ŒèŠå¤©è®°å½•åœ¨ prompt ä¸­çš„ keyï¼Œå› ä¸ºè¦è‡ªåŠ¨çš„æŠŠèŠå¤©è®°å½•æ³¨å…¥åˆ° prompt ä¸­ã€‚\n",
    "outputMessagesKeyï¼Œå› ä¸ºæˆ‘ä»¬çš„ chain åªæœ‰ä¸€ä¸ªè¾“å‡ºå°±çœç•¥äº†ï¼Œå¦‚æœæœ‰å¤šä¸ªè¾“å‡ºéœ€è¦æŒ‡å®šå“ªä¸ªæ˜¯ llm çš„å›å¤ï¼Œä¹Ÿå°±æ˜¯éœ€è¦å­˜å‚¨çš„ä¿¡æ¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  \"id\": \"f465900d-63c9-485d-a9d1-0b604cc98173\",\n",
       "  \"content\": \"Hi, Kai! Nice to meet you. How can I assist you today? ğŸ˜Š\",\n",
       "  \"additional_kwargs\": {},\n",
       "  \"response_metadata\": {\n",
       "    \"tokenUsage\": {\n",
       "      \"promptTokens\": 25,\n",
       "      \"completionTokens\": 18,\n",
       "      \"totalTokens\": 43\n",
       "    },\n",
       "    \"finish_reason\": \"stop\",\n",
       "    \"model_name\": \"deepseek-chat\",\n",
       "    \"usage\": {\n",
       "      \"prompt_tokens\": 25,\n",
       "      \"completion_tokens\": 18,\n",
       "      \"total_tokens\": 43,\n",
       "      \"prompt_tokens_details\": {\n",
       "        \"cached_tokens\": 0\n",
       "      },\n",
       "      \"prompt_cache_hit_tokens\": 0,\n",
       "      \"prompt_cache_miss_tokens\": 25\n",
       "    },\n",
       "    \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
       "  },\n",
       "  \"tool_calls\": [],\n",
       "  \"invalid_tool_calls\": [],\n",
       "  \"usage_metadata\": {\n",
       "    \"output_tokens\": 18,\n",
       "    \"input_tokens\": 25,\n",
       "    \"total_tokens\": 43,\n",
       "    \"input_token_details\": {\n",
       "      \"cache_read\": 0\n",
       "    },\n",
       "    \"output_token_details\": {}\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// è‡ªåŠ¨ç»´æŠ¤chat historyï¼Œç”± RunnableWithMessageHistory ç»™ä»»æ„ chain åŒ…è£¹ä¸€å±‚ï¼Œå°±èƒ½æ·»åŠ èŠå¤©è®°å½•ç®¡ç†çš„èƒ½åŠ›\n",
    "import { RunnableWithMessageHistory } from \"@langchain/core/runnables\";\n",
    "const chatModel = new ChatDeepSeek({\n",
    "    model: \"deepseek-chat\",\n",
    "  });\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability.\"],\n",
    "    new MessagesPlaceholder(\"history_message\"),\n",
    "    [\"human\",\"{input}\"]\n",
    "]);\n",
    "\n",
    "const history = new ChatMessageHistory();\n",
    "const chain = prompt.pipe(chatModel)\n",
    "\n",
    "const chainWithHistory = new RunnableWithMessageHistory({\n",
    "  runnable: chain,\n",
    "  getMessageHistory: (_sessionId) => history,\n",
    "  inputMessagesKey: \"input\",\n",
    "  historyMessagesKey: \"history_message\",\n",
    "});\n",
    "const res1 = await chainWithHistory.invoke({\n",
    "    input: \"hi, my name is Kai\"\n",
    "},{\n",
    "    configurable: { sessionId: \"none\" }\n",
    "})\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  \"id\": \"f4048d34-10dd-41c2-9e29-595e8d31918a\",\n",
       "  \"content\": \"ä½ çš„åå­—å«Kaiã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š\",\n",
       "  \"additional_kwargs\": {},\n",
       "  \"response_metadata\": {\n",
       "    \"tokenUsage\": {\n",
       "      \"promptTokens\": 50,\n",
       "      \"completionTokens\": 14,\n",
       "      \"totalTokens\": 64\n",
       "    },\n",
       "    \"finish_reason\": \"stop\",\n",
       "    \"model_name\": \"deepseek-chat\",\n",
       "    \"usage\": {\n",
       "      \"prompt_tokens\": 50,\n",
       "      \"completion_tokens\": 14,\n",
       "      \"total_tokens\": 64,\n",
       "      \"prompt_tokens_details\": {\n",
       "        \"cached_tokens\": 0\n",
       "      },\n",
       "      \"prompt_cache_hit_tokens\": 0,\n",
       "      \"prompt_cache_miss_tokens\": 50\n",
       "    },\n",
       "    \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
       "  },\n",
       "  \"tool_calls\": [],\n",
       "  \"invalid_tool_calls\": [],\n",
       "  \"usage_metadata\": {\n",
       "    \"output_tokens\": 14,\n",
       "    \"input_tokens\": 50,\n",
       "    \"total_tokens\": 64,\n",
       "    \"input_token_details\": {\n",
       "      \"cache_read\": 0\n",
       "    },\n",
       "    \"output_token_details\": {}\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const res2 = await chainWithHistory.invoke({\n",
    "    input: \"æˆ‘çš„åå­—å«ä»€ä¹ˆï¼Ÿ\"\n",
    "},{\n",
    "    configurable: { sessionId: \"none\" }\n",
    "})\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  HumanMessage {\n",
       "    \"content\": \"hi, my name is Kai\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    \"id\": \"f465900d-63c9-485d-a9d1-0b604cc98173\",\n",
       "    \"content\": \"Hi, Kai! Nice to meet you. How can I assist you today? ğŸ˜Š\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {\n",
       "      \"tokenUsage\": {\n",
       "        \"promptTokens\": 25,\n",
       "        \"completionTokens\": 18,\n",
       "        \"totalTokens\": 43\n",
       "      },\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"model_name\": \"deepseek-chat\",\n",
       "      \"usage\": {\n",
       "        \"prompt_tokens\": 25,\n",
       "        \"completion_tokens\": 18,\n",
       "        \"total_tokens\": 43,\n",
       "        \"prompt_tokens_details\": {\n",
       "          \"cached_tokens\": 0\n",
       "        },\n",
       "        \"prompt_cache_hit_tokens\": 0,\n",
       "        \"prompt_cache_miss_tokens\": 25\n",
       "      },\n",
       "      \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
       "    },\n",
       "    \"tool_calls\": [],\n",
       "    \"invalid_tool_calls\": [],\n",
       "    \"usage_metadata\": {\n",
       "      \"output_tokens\": 18,\n",
       "      \"input_tokens\": 25,\n",
       "      \"total_tokens\": 43,\n",
       "      \"input_token_details\": {\n",
       "        \"cache_read\": 0\n",
       "      },\n",
       "      \"output_token_details\": {}\n",
       "    }\n",
       "  },\n",
       "  HumanMessage {\n",
       "    \"content\": \"æˆ‘çš„åå­—å«ä»€ä¹ˆï¼Ÿ\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    \"id\": \"f4048d34-10dd-41c2-9e29-595e8d31918a\",\n",
       "    \"content\": \"ä½ çš„åå­—å«Kaiã€‚æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®ä½ çš„å—ï¼ŸğŸ˜Š\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {\n",
       "      \"tokenUsage\": {\n",
       "        \"promptTokens\": 50,\n",
       "        \"completionTokens\": 14,\n",
       "        \"totalTokens\": 64\n",
       "      },\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"model_name\": \"deepseek-chat\",\n",
       "      \"usage\": {\n",
       "        \"prompt_tokens\": 50,\n",
       "        \"completion_tokens\": 14,\n",
       "        \"total_tokens\": 64,\n",
       "        \"prompt_tokens_details\": {\n",
       "          \"cached_tokens\": 0\n",
       "        },\n",
       "        \"prompt_cache_hit_tokens\": 0,\n",
       "        \"prompt_cache_miss_tokens\": 50\n",
       "      },\n",
       "      \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
       "    },\n",
       "    \"tool_calls\": [],\n",
       "    \"invalid_tool_calls\": [],\n",
       "    \"usage_metadata\": {\n",
       "      \"output_tokens\": 14,\n",
       "      \"input_tokens\": 50,\n",
       "      \"total_tokens\": 64,\n",
       "      \"input_token_details\": {\n",
       "        \"cache_read\": 0\n",
       "      },\n",
       "      \"output_token_details\": {}\n",
       "    }\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await history.getMessages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"The person mentioned that they are an 18-year-old male.\"\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// RunnableWithMessageHistory æ˜¯å°†å†å²è®°å½•å®Œæ•´çš„ä¼ é€’åˆ° llmä¸­ï¼Œæˆ‘ä»¬å¯ä»¥å¯¹ llm çš„å†å²è®°å½•è¿›è¡Œæ›´å¤šæ“ä½œï¼Œä¾‹å¦‚åªä¼ é€’æœ€è¿‘çš„ k æ¡å†å²è®°å½•ç­‰ã€‚\n",
    "\n",
    "// ä¸‹é¢æ˜¯ä¸€ä¸ªæ€»ç»“å†å²è®°å½•çš„chainæ¥æ”¶ä¸¤ä¸ªå‚æ•°ï¼Œ\n",
    "// summaryï¼Œä¸Šä¸€æ¬¡æ€»ç»“çš„ä¿¡æ¯\n",
    "// new_linesï¼Œç”¨æˆ·å’Œ llm æ–°çš„å›å¤\n",
    "import {RunnableSequence} from \"@langchain/core/runnables\";\n",
    "import {StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const summaryModel = new ChatDeepSeek({\n",
    "    model:'deepseek-chat'\n",
    "});\n",
    "const summaryPrompt = ChatPromptTemplate.fromTemplate(`\n",
    "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary\n",
    "\n",
    "Current summary:\n",
    "{summary}\n",
    "\n",
    "New lines of conversation:\n",
    "{new_lines}\n",
    "\n",
    "New summary:\n",
    "`); \n",
    "\n",
    "const summaryChain = RunnableSequence.from([\n",
    "    summaryPrompt,\n",
    "    summaryModel,\n",
    "    new StringOutputParser(),\n",
    "])\n",
    "\n",
    "const newSummary = await summaryChain.invoke({\n",
    "    summary:\"\",\n",
    "    new_lines: \"I'm 18\"\n",
    "})\n",
    "await summaryChain.invoke({\n",
    "    summary: newSummary,\n",
    "    new_lines: \"I'm male\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬ä½¿ç”¨ new RunnablePassthrough({func: (input)=> void})ï¼Œæ˜¯æœ‰ä¸¤ä¸ªç›®çš„ï¼š\n",
    "\n",
    "- å¦‚æœæˆ‘ä»¬åªå†™ new RunnablePassthrough()ï¼Œé‚£å°±æ˜¯æŠŠç”¨æˆ·è¾“å…¥çš„ input å†ä¼ é€’åˆ°ä¸‹ä¸€ä¸ª runnable èŠ‚ç‚¹ä¸­ï¼Œä¸åšä»»ä½•æ“ä½œã€‚å› ä¸º RunnableMap è¿”å›å€¼æ˜¯å¯¹å…¶ä¸­æ¯ä¸ª chain æ‰§è¡Œï¼Œç„¶åå°†è¿”å›å€¼ä½œä¸ºç»“æœä¼ é€’ç»™ä¸‹ä¸€ä¸ª runnable èŠ‚ç‚¹ï¼Œå¦‚æœæˆ‘ä»¬ä¸å¯¹ input ä½¿ç”¨ RunnablePassthrough åˆ™ä¸‹ä¸ªèŠ‚ç‚¹å°±æ‹¿ä¸åˆ° input çš„å€¼\n",
    "- new RunnablePassthrough({func: (input)=> void}) ä¸­çš„ func å‡½æ•°æ˜¯åœ¨ä¼ é€’ input çš„è¿‡ç¨‹ä¸­ï¼Œæ‰§è¡Œä¸€ä¸ªå‡½æ•°ï¼Œè¿™ä¸ªå‡½æ•°è¿”å›å€¼æ˜¯ voidï¼Œä¹Ÿå°±æ˜¯æ— è®ºå…¶å†…å®¹æ˜¯ä»€ä¹ˆï¼Œéƒ½ä¸ä¼šå¯¹ input é€ æˆå½±å“ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import {RunnablePassthrough} from \"@langchain/core/runnables\";\n",
    "import {getBufferString} from \"langchain/memory\";\n",
    "const chatModel = new ChatDeepSeek({\n",
    "    model:'deepseek-chat'\n",
    "});\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", `You are a helpful assistant. Answer all questions to the best of your ability.\n",
    "\n",
    "    Here is the chat history summary:\n",
    "    {history_summary}\n",
    "    `],\n",
    "    [\"human\",\"{input}\"]\n",
    "]);\n",
    "let summary = \"\"\n",
    "const history = new ChatMessageHistory();\n",
    "\n",
    "const chatChain = RunnableSequence.from([\n",
    "    {\n",
    "        input: new RunnablePassthrough({\n",
    "             func: (input) => history.addUserMessage(input)\n",
    "        })\n",
    "    },\n",
    "    RunnablePassthrough.assign({\n",
    "        history_summary: () => summary\n",
    "    }),\n",
    "    chatPrompt,\n",
    "    chatModel,\n",
    "    new StringOutputParser(),\n",
    "    new RunnablePassthrough({\n",
    "        func: async (input) => {\n",
    "            history.addAIChatMessage(input)\n",
    "            const messages = await history.getMessages()\n",
    "            const new_lines = getBufferString(messages)\n",
    "            const newSummary = await summaryChain.invoke({\n",
    "                summary,\n",
    "                new_lines\n",
    "            })\n",
    "            history.clear()\n",
    "            summary = newSummary      \n",
    "        }\n",
    "    })\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"ä½ ç°åœ¨é¥¿äº†çš„è¯ï¼Œå¯ä»¥è€ƒè™‘ä»¥ä¸‹å‡ ç§é€‰æ‹©ï¼š\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"1. **è‡ªå·±åšé¥­**ï¼šå¦‚æœä½ æœ‰é£Ÿæï¼Œå¯ä»¥åšä¸€äº›ç®€å•çš„é¥­èœï¼Œæ¯”å¦‚ç‚’é¥­ã€é¢æ¡ã€ç…è›‹ç­‰ã€‚\\n\"\u001b[39m +\n",
       "  \u001b[32m\"2. **ç‚¹å¤–å–**ï¼šå¦‚æœä½ ä¸æƒ³åšé¥­ï¼Œå¯ä»¥ç‚¹å¤–å–ï¼Œé€‰æ‹©ä½ å–œæ¬¢çš„é¤å…å’Œèœå“ã€‚\\n\"\u001b[39m +\n",
       "  \u001b[32m\"3. **å¤–å‡ºå°±é¤**ï¼šå¦‚æœä½ æœ‰æ—¶é—´ï¼Œå¯ä»¥å‡ºå»æ‰¾ä¸€å®¶é¤å…åƒé¥­ï¼Œäº«å—ä¸€ä¸‹å¤–é¢çš„ç¾é£Ÿã€‚\\n\"\u001b[39m +\n",
       "  \u001b[32m\"4. **é›¶é£Ÿ**ï¼šå¦‚æœä½ åªæ˜¯æœ‰ç‚¹é¥¿ï¼Œå¯ä»¥å…ˆåƒç‚¹é›¶é£Ÿå«å«è‚šå­ï¼Œæ¯”å¦‚æ°´æœã€åšæœã€é¥¼å¹²ç­‰ã€‚\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"ä½ æ›´å€¾å‘äºå“ªç§é€‰æ‹©å‘¢ï¼Ÿ\"\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chatChain.invoke(\"æˆ‘ç°åœ¨é¥¿äº†\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"æ–¹ä¾¿é¢ç¡®å®æ˜¯ä¸€ä¸ªå¿«é€Ÿè§£å†³é¥¥é¥¿çš„å¥½é€‰æ‹©ï¼ä½ å¯ä»¥æ ¹æ®è‡ªå·±çš„å£å‘³é€‰æ‹©ä¸åŒçš„è°ƒå‘³åŒ…ï¼Œæˆ–è€…åŠ å…¥ä¸€äº›é¢å¤–çš„é£Ÿææ¥æå‡å£æ„Ÿã€‚æ¯”å¦‚ï¼Œä½ å¯ä»¥åŠ ä¸€ä¸ªé¸¡è›‹ã€ä¸€äº›è”¬èœï¼ˆå¦‚é’èœã€èƒ¡èåœï¼‰ã€æˆ–è€…ä¸€äº›è‚‰ç±»ï¼ˆå¦‚ç«è…¿ã€é¸¡è‚‰ï¼‰ã€‚è¿™æ ·ä¸ä»…èƒ½è®©æ–¹ä¾¿é¢æ›´ç¾å‘³ï¼Œè¿˜èƒ½å¢åŠ è¥å…»ã€‚\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"å¦‚æœä½ æœ‰æ—¶é—´å’Œæ¡ä»¶ï¼Œå¯ä»¥å°è¯•ä»¥ä¸‹å‡ ç§å‡çº§ç‰ˆæ–¹ä¾¿é¢çš„åšæ³•ï¼š\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"1. **é¸¡è›‹æ–¹ä¾¿é¢**ï¼šåœ¨ç…®é¢çš„æ—¶å€™æ‰“å…¥ä¸€ä¸ªé¸¡è›‹ï¼Œå¯ä»¥åšæˆè·åŒ…è›‹æˆ–è€…æ‰“æ•£æˆè›‹èŠ±ã€‚\\n\"\u001b[39m +\n",
       "  \u001b[32m\"2. **è”¬èœæ–¹ä¾¿é¢**ï¼šåŠ å…¥ä¸€äº›æ–°é²œçš„è”¬èœï¼Œæ¯”å¦‚è èœã€è±†èŠ½ã€è˜‘è‡ç­‰ï¼Œå¢åŠ çº¤ç»´å’Œç»´ç”Ÿç´ ã€‚\\n\"\u001b[39m +\n",
       "  \u001b[32m\"3. **è‚‰ç±»æ–¹ä¾¿é¢**ï¼šåŠ å…¥ä¸€äº›ç†Ÿé£Ÿè‚‰ç±»ï¼Œå¦‚ç«è…¿ã€åŸ¹æ ¹ã€é¸¡è‚‰ç‰‡ç­‰ï¼Œå¢åŠ è›‹ç™½è´¨ã€‚\\n\"\u001b[39m +\n",
       "  \u001b[32m\"4. **èŠå£«æ–¹ä¾¿é¢**ï¼šåœ¨ç…®å¥½çš„æ–¹ä¾¿é¢ä¸Šæ’’ä¸Šä¸€äº›èŠå£«ç‰‡ï¼Œç­‰èŠå£«èåŒ–åæ…æ‹Œå‡åŒ€ï¼Œå‘³é“ä¼šæ›´æµ“éƒã€‚\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"ä½ å¹³æ—¶å–œæ¬¢æ€ä¹ˆåƒæ–¹ä¾¿é¢å‘¢ï¼Ÿæœ‰æ²¡æœ‰ç‰¹åˆ«å–œæ¬¢çš„å£å‘³æˆ–æ­é…ï¼Ÿ\"\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chatChain.invoke(\"æˆ‘ä»Šå¤©æƒ³åƒæ–¹ä¾¿é¢\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"The human mentions feeling hungry and expresses a craving for instant noodles. The AI acknowledges this as a quick solution and suggests enhancing the noodles by adding ingredients like eggs, vegetables, or meat to improve flavor and nutrition. The AI also provides specific ideas for upgrading instant noodles, such as adding eggs, vegetables, meat, or cheese, and asks the human about their preferred way of eating instant noodles, including any favorite flavors or combinations. \\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"Summary: The human craves instant noodles, and the AI recommends enhancing them with additional ingredients like eggs, vegetables, or meat for better taste and nutrition. The AI offers specific upgrade ideas and asks about the human's preferred instant noodle preparation and flavors.\"\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
