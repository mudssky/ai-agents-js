{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  HumanMessage {\n",
       "    \"content\": \"hi\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    \"content\": \"What can I do for you?\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {},\n",
       "    \"tool_calls\": [],\n",
       "    \"invalid_tool_calls\": []\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatMessageHistory } from \"langchain/stores/message/in_memory\";\n",
    "import { HumanMessage, AIMessage } from \"@langchain/core/messages\";\n",
    "const history = new ChatMessageHistory();\n",
    "await history.addMessage(new HumanMessage(\"hi\"));\n",
    "await history.addMessage(new AIMessage(\"What can I do for you?\"));\n",
    "const messages = await history.getMessages();\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```typescript\n",
    "export abstract class BaseChatMessageHistory extends Serializable {\n",
    "  public abstract getMessages(): Promise<BaseMessage[]>;\n",
    "\n",
    "  public abstract addMessage(message: BaseMessage): Promise<void>;\n",
    "\n",
    "  public abstract addUserMessage(message: string): Promise<void>;\n",
    "\n",
    "  public abstract addAIChatMessage(message: string): Promise<void>;\n",
    "\n",
    "  public abstract clear(): Promise<void>;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  \"id\": \"850eb88b-83fd-4c00-a178-e0ad6d4d23be\",\n",
       "  \"content\": \"Hi Kai! It's great to meet you. How can I assist you today? Whether you have questions, need advice, or just want to chat, I'm here to help!\",\n",
       "  \"additional_kwargs\": {},\n",
       "  \"response_metadata\": {\n",
       "    \"tokenUsage\": {\n",
       "      \"promptTokens\": 63,\n",
       "      \"completionTokens\": 37,\n",
       "      \"totalTokens\": 100\n",
       "    },\n",
       "    \"finish_reason\": \"stop\",\n",
       "    \"model_name\": \"deepseek-chat\",\n",
       "    \"usage\": {\n",
       "      \"prompt_tokens\": 63,\n",
       "      \"completion_tokens\": 37,\n",
       "      \"total_tokens\": 100,\n",
       "      \"prompt_tokens_details\": {\n",
       "        \"cached_tokens\": 0\n",
       "      },\n",
       "      \"prompt_cache_hit_tokens\": 0,\n",
       "      \"prompt_cache_miss_tokens\": 63\n",
       "    },\n",
       "    \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
       "  },\n",
       "  \"tool_calls\": [],\n",
       "  \"invalid_tool_calls\": [],\n",
       "  \"usage_metadata\": {\n",
       "    \"output_tokens\": 37,\n",
       "    \"input_tokens\": 63,\n",
       "    \"total_tokens\": 100,\n",
       "    \"input_token_details\": {\n",
       "      \"cache_read\": 0\n",
       "    },\n",
       "    \"output_token_details\": {}\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 手动维护\n",
    "import { ChatPromptTemplate, MessagesPlaceholder } from \"@langchain/core/prompts\";\n",
    "import { ChatDeepSeek } from \"@langchain/deepseek\";\n",
    "\n",
    "const chatModel = new ChatDeepSeek({\n",
    "    model: \"deepseek-chat\",\n",
    "  });\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", `You are a helpful assistant. Answer all questions to the best of your ability.\n",
    "    You are talkative and provides lots of specific details from its context. \n",
    "    If the you does not know the answer to a question, it truthfully says you do not know.`],\n",
    "    new MessagesPlaceholder(\"history_message\"),\n",
    "]);\n",
    "\n",
    "const chain = prompt.pipe(chatModel);\n",
    "\n",
    "\n",
    "const history = new ChatMessageHistory();\n",
    "await history.addMessage(new HumanMessage(\"hi, my name is Kai\"));\n",
    "const res1 = await chain.invoke({\n",
    "    history_message: await history.getMessages()\n",
    "})\n",
    "res1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  \"id\": \"a9afee9a-b08d-464c-88e4-b0e29ed111bf\",\n",
       "  \"content\": \"Your name is Kai! You introduced yourself earlier by saying, \\\"Hi, my name is Kai.\\\" If there's anything specific you'd like to discuss or ask, feel free to let me know! 😊\",\n",
       "  \"additional_kwargs\": {},\n",
       "  \"response_metadata\": {\n",
       "    \"tokenUsage\": {\n",
       "      \"promptTokens\": 108,\n",
       "      \"completionTokens\": 42,\n",
       "      \"totalTokens\": 150\n",
       "    },\n",
       "    \"finish_reason\": \"stop\",\n",
       "    \"model_name\": \"deepseek-chat\",\n",
       "    \"usage\": {\n",
       "      \"prompt_tokens\": 108,\n",
       "      \"completion_tokens\": 42,\n",
       "      \"total_tokens\": 150,\n",
       "      \"prompt_tokens_details\": {\n",
       "        \"cached_tokens\": 64\n",
       "      },\n",
       "      \"prompt_cache_hit_tokens\": 64,\n",
       "      \"prompt_cache_miss_tokens\": 44\n",
       "    },\n",
       "    \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
       "  },\n",
       "  \"tool_calls\": [],\n",
       "  \"invalid_tool_calls\": [],\n",
       "  \"usage_metadata\": {\n",
       "    \"output_tokens\": 42,\n",
       "    \"input_tokens\": 108,\n",
       "    \"total_tokens\": 150,\n",
       "    \"input_token_details\": {\n",
       "      \"cache_read\": 64\n",
       "    },\n",
       "    \"output_token_details\": {}\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 这里把对话的结果也手动添加到历史记录中\n",
    "await history.addMessage(res1)\n",
    "await history.addMessage(new HumanMessage(\"What is my name?\"));\n",
    "const res2 = await chain.invoke({\n",
    "    history_message: await history.getMessages()\n",
    "})\n",
    "res2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RunnableWithMessageHistory 有几个参数：\n",
    "- runnable 就是需要被包裹的 chain，可以是任意 chain\n",
    "- getMessageHistory 接收一个函数，函数需要根据传入的 _sessionId，去获取对应的 ChatMessageHistory 对象，这里我们没有 session 管理，所以就返回默认的对象\n",
    "- inputMessagesKey 用户传入的信息 key 的名称，因为 RunnableWithMessageHistory 要自动记录用户和 llm 发送的信息，所以需要在这里声明用户以什么 key 传入信息\n",
    "- historyMessagesKey，聊天记录在 prompt 中的 key，因为要自动的把聊天记录注入到 prompt 中。\n",
    "outputMessagesKey，因为我们的 chain 只有一个输出就省略了，如果有多个输出需要指定哪个是 llm 的回复，也就是需要存储的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  \"id\": \"f465900d-63c9-485d-a9d1-0b604cc98173\",\n",
       "  \"content\": \"Hi, Kai! Nice to meet you. How can I assist you today? 😊\",\n",
       "  \"additional_kwargs\": {},\n",
       "  \"response_metadata\": {\n",
       "    \"tokenUsage\": {\n",
       "      \"promptTokens\": 25,\n",
       "      \"completionTokens\": 18,\n",
       "      \"totalTokens\": 43\n",
       "    },\n",
       "    \"finish_reason\": \"stop\",\n",
       "    \"model_name\": \"deepseek-chat\",\n",
       "    \"usage\": {\n",
       "      \"prompt_tokens\": 25,\n",
       "      \"completion_tokens\": 18,\n",
       "      \"total_tokens\": 43,\n",
       "      \"prompt_tokens_details\": {\n",
       "        \"cached_tokens\": 0\n",
       "      },\n",
       "      \"prompt_cache_hit_tokens\": 0,\n",
       "      \"prompt_cache_miss_tokens\": 25\n",
       "    },\n",
       "    \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
       "  },\n",
       "  \"tool_calls\": [],\n",
       "  \"invalid_tool_calls\": [],\n",
       "  \"usage_metadata\": {\n",
       "    \"output_tokens\": 18,\n",
       "    \"input_tokens\": 25,\n",
       "    \"total_tokens\": 43,\n",
       "    \"input_token_details\": {\n",
       "      \"cache_read\": 0\n",
       "    },\n",
       "    \"output_token_details\": {}\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// 自动维护chat history，由 RunnableWithMessageHistory 给任意 chain 包裹一层，就能添加聊天记录管理的能力\n",
    "import { RunnableWithMessageHistory } from \"@langchain/core/runnables\";\n",
    "const chatModel = new ChatDeepSeek({\n",
    "    model: \"deepseek-chat\",\n",
    "  });\n",
    "const prompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", \"You are a helpful assistant. Answer all questions to the best of your ability.\"],\n",
    "    new MessagesPlaceholder(\"history_message\"),\n",
    "    [\"human\",\"{input}\"]\n",
    "]);\n",
    "\n",
    "const history = new ChatMessageHistory();\n",
    "const chain = prompt.pipe(chatModel)\n",
    "\n",
    "const chainWithHistory = new RunnableWithMessageHistory({\n",
    "  runnable: chain,\n",
    "  getMessageHistory: (_sessionId) => history,\n",
    "  inputMessagesKey: \"input\",\n",
    "  historyMessagesKey: \"history_message\",\n",
    "});\n",
    "const res1 = await chainWithHistory.invoke({\n",
    "    input: \"hi, my name is Kai\"\n",
    "},{\n",
    "    configurable: { sessionId: \"none\" }\n",
    "})\n",
    "res1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  \"id\": \"f4048d34-10dd-41c2-9e29-595e8d31918a\",\n",
       "  \"content\": \"你的名字叫Kai。有什么我可以帮你的吗？😊\",\n",
       "  \"additional_kwargs\": {},\n",
       "  \"response_metadata\": {\n",
       "    \"tokenUsage\": {\n",
       "      \"promptTokens\": 50,\n",
       "      \"completionTokens\": 14,\n",
       "      \"totalTokens\": 64\n",
       "    },\n",
       "    \"finish_reason\": \"stop\",\n",
       "    \"model_name\": \"deepseek-chat\",\n",
       "    \"usage\": {\n",
       "      \"prompt_tokens\": 50,\n",
       "      \"completion_tokens\": 14,\n",
       "      \"total_tokens\": 64,\n",
       "      \"prompt_tokens_details\": {\n",
       "        \"cached_tokens\": 0\n",
       "      },\n",
       "      \"prompt_cache_hit_tokens\": 0,\n",
       "      \"prompt_cache_miss_tokens\": 50\n",
       "    },\n",
       "    \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
       "  },\n",
       "  \"tool_calls\": [],\n",
       "  \"invalid_tool_calls\": [],\n",
       "  \"usage_metadata\": {\n",
       "    \"output_tokens\": 14,\n",
       "    \"input_tokens\": 50,\n",
       "    \"total_tokens\": 64,\n",
       "    \"input_token_details\": {\n",
       "      \"cache_read\": 0\n",
       "    },\n",
       "    \"output_token_details\": {}\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const res2 = await chainWithHistory.invoke({\n",
    "    input: \"我的名字叫什么？\"\n",
    "},{\n",
    "    configurable: { sessionId: \"none\" }\n",
    "})\n",
    "res2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  HumanMessage {\n",
       "    \"content\": \"hi, my name is Kai\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    \"id\": \"f465900d-63c9-485d-a9d1-0b604cc98173\",\n",
       "    \"content\": \"Hi, Kai! Nice to meet you. How can I assist you today? 😊\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {\n",
       "      \"tokenUsage\": {\n",
       "        \"promptTokens\": 25,\n",
       "        \"completionTokens\": 18,\n",
       "        \"totalTokens\": 43\n",
       "      },\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"model_name\": \"deepseek-chat\",\n",
       "      \"usage\": {\n",
       "        \"prompt_tokens\": 25,\n",
       "        \"completion_tokens\": 18,\n",
       "        \"total_tokens\": 43,\n",
       "        \"prompt_tokens_details\": {\n",
       "          \"cached_tokens\": 0\n",
       "        },\n",
       "        \"prompt_cache_hit_tokens\": 0,\n",
       "        \"prompt_cache_miss_tokens\": 25\n",
       "      },\n",
       "      \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
       "    },\n",
       "    \"tool_calls\": [],\n",
       "    \"invalid_tool_calls\": [],\n",
       "    \"usage_metadata\": {\n",
       "      \"output_tokens\": 18,\n",
       "      \"input_tokens\": 25,\n",
       "      \"total_tokens\": 43,\n",
       "      \"input_token_details\": {\n",
       "        \"cache_read\": 0\n",
       "      },\n",
       "      \"output_token_details\": {}\n",
       "    }\n",
       "  },\n",
       "  HumanMessage {\n",
       "    \"content\": \"我的名字叫什么？\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {}\n",
       "  },\n",
       "  AIMessage {\n",
       "    \"id\": \"f4048d34-10dd-41c2-9e29-595e8d31918a\",\n",
       "    \"content\": \"你的名字叫Kai。有什么我可以帮你的吗？😊\",\n",
       "    \"additional_kwargs\": {},\n",
       "    \"response_metadata\": {\n",
       "      \"tokenUsage\": {\n",
       "        \"promptTokens\": 50,\n",
       "        \"completionTokens\": 14,\n",
       "        \"totalTokens\": 64\n",
       "      },\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"model_name\": \"deepseek-chat\",\n",
       "      \"usage\": {\n",
       "        \"prompt_tokens\": 50,\n",
       "        \"completion_tokens\": 14,\n",
       "        \"total_tokens\": 64,\n",
       "        \"prompt_tokens_details\": {\n",
       "          \"cached_tokens\": 0\n",
       "        },\n",
       "        \"prompt_cache_hit_tokens\": 0,\n",
       "        \"prompt_cache_miss_tokens\": 50\n",
       "      },\n",
       "      \"system_fingerprint\": \"fp_3a5770e1b4_prod0225\"\n",
       "    },\n",
       "    \"tool_calls\": [],\n",
       "    \"invalid_tool_calls\": [],\n",
       "    \"usage_metadata\": {\n",
       "      \"output_tokens\": 14,\n",
       "      \"input_tokens\": 50,\n",
       "      \"total_tokens\": 64,\n",
       "      \"input_token_details\": {\n",
       "        \"cache_read\": 0\n",
       "      },\n",
       "      \"output_token_details\": {}\n",
       "    }\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await history.getMessages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"The person mentioned that they are an 18-year-old male.\"\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// RunnableWithMessageHistory 是将历史记录完整的传递到 llm中，我们可以对 llm 的历史记录进行更多操作，例如只传递最近的 k 条历史记录等。\n",
    "\n",
    "// 下面是一个总结历史记录的chain接收两个参数，\n",
    "// summary，上一次总结的信息\n",
    "// new_lines，用户和 llm 新的回复\n",
    "import {RunnableSequence} from \"@langchain/core/runnables\";\n",
    "import {StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const summaryModel = new ChatDeepSeek({\n",
    "    model:'deepseek-chat'\n",
    "});\n",
    "const summaryPrompt = ChatPromptTemplate.fromTemplate(`\n",
    "Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary\n",
    "\n",
    "Current summary:\n",
    "{summary}\n",
    "\n",
    "New lines of conversation:\n",
    "{new_lines}\n",
    "\n",
    "New summary:\n",
    "`); \n",
    "\n",
    "const summaryChain = RunnableSequence.from([\n",
    "    summaryPrompt,\n",
    "    summaryModel,\n",
    "    new StringOutputParser(),\n",
    "])\n",
    "\n",
    "const newSummary = await summaryChain.invoke({\n",
    "    summary:\"\",\n",
    "    new_lines: \"I'm 18\"\n",
    "})\n",
    "await summaryChain.invoke({\n",
    "    summary: newSummary,\n",
    "    new_lines: \"I'm male\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用 new RunnablePassthrough({func: (input)=> void})，是有两个目的：\n",
    "\n",
    "- 如果我们只写 new RunnablePassthrough()，那就是把用户输入的 input 再传递到下一个 runnable 节点中，不做任何操作。因为 RunnableMap 返回值是对其中每个 chain 执行，然后将返回值作为结果传递给下一个 runnable 节点，如果我们不对 input 使用 RunnablePassthrough 则下个节点就拿不到 input 的值\n",
    "- new RunnablePassthrough({func: (input)=> void}) 中的 func 函数是在传递 input 的过程中，执行一个函数，这个函数返回值是 void，也就是无论其内容是什么，都不会对 input 造成影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import {RunnablePassthrough} from \"@langchain/core/runnables\";\n",
    "import {getBufferString} from \"langchain/memory\";\n",
    "const chatModel = new ChatDeepSeek({\n",
    "    model:'deepseek-chat'\n",
    "});\n",
    "const chatPrompt = ChatPromptTemplate.fromMessages([\n",
    "    [\"system\", `You are a helpful assistant. Answer all questions to the best of your ability.\n",
    "\n",
    "    Here is the chat history summary:\n",
    "    {history_summary}\n",
    "    `],\n",
    "    [\"human\",\"{input}\"]\n",
    "]);\n",
    "let summary = \"\"\n",
    "const history = new ChatMessageHistory();\n",
    "\n",
    "const chatChain = RunnableSequence.from([\n",
    "    {\n",
    "        input: new RunnablePassthrough({\n",
    "             func: (input) => history.addUserMessage(input)\n",
    "        })\n",
    "    },\n",
    "    RunnablePassthrough.assign({\n",
    "        history_summary: () => summary\n",
    "    }),\n",
    "    chatPrompt,\n",
    "    chatModel,\n",
    "    new StringOutputParser(),\n",
    "    new RunnablePassthrough({\n",
    "        func: async (input) => {\n",
    "            history.addAIChatMessage(input)\n",
    "            const messages = await history.getMessages()\n",
    "            const new_lines = getBufferString(messages)\n",
    "            const newSummary = await summaryChain.invoke({\n",
    "                summary,\n",
    "                new_lines\n",
    "            })\n",
    "            history.clear()\n",
    "            summary = newSummary      \n",
    "        }\n",
    "    })\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"你现在饿了的话，可以考虑以下几种选择：\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"1. **自己做饭**：如果你有食材，可以做一些简单的饭菜，比如炒饭、面条、煎蛋等。\\n\"\u001b[39m +\n",
       "  \u001b[32m\"2. **点外卖**：如果你不想做饭，可以点外卖，选择你喜欢的餐厅和菜品。\\n\"\u001b[39m +\n",
       "  \u001b[32m\"3. **外出就餐**：如果你有时间，可以出去找一家餐厅吃饭，享受一下外面的美食。\\n\"\u001b[39m +\n",
       "  \u001b[32m\"4. **零食**：如果你只是有点饿，可以先吃点零食垫垫肚子，比如水果、坚果、饼干等。\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"你更倾向于哪种选择呢？\"\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chatChain.invoke(\"我现在饿了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"方便面确实是一个快速解决饥饿的好选择！你可以根据自己的口味选择不同的调味包，或者加入一些额外的食材来提升口感。比如，你可以加一个鸡蛋、一些蔬菜（如青菜、胡萝卜）、或者一些肉类（如火腿、鸡肉）。这样不仅能让方便面更美味，还能增加营养。\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"如果你有时间和条件，可以尝试以下几种升级版方便面的做法：\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"1. **鸡蛋方便面**：在煮面的时候打入一个鸡蛋，可以做成荷包蛋或者打散成蛋花。\\n\"\u001b[39m +\n",
       "  \u001b[32m\"2. **蔬菜方便面**：加入一些新鲜的蔬菜，比如菠菜、豆芽、蘑菇等，增加纤维和维生素。\\n\"\u001b[39m +\n",
       "  \u001b[32m\"3. **肉类方便面**：加入一些熟食肉类，如火腿、培根、鸡肉片等，增加蛋白质。\\n\"\u001b[39m +\n",
       "  \u001b[32m\"4. **芝士方便面**：在煮好的方便面上撒上一些芝士片，等芝士融化后搅拌均匀，味道会更浓郁。\\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"你平时喜欢怎么吃方便面呢？有没有特别喜欢的口味或搭配？\"\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await chatChain.invoke(\"我今天想吃方便面\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32m\"The human mentions feeling hungry and expresses a craving for instant noodles. The AI acknowledges this as a quick solution and suggests enhancing the noodles by adding ingredients like eggs, vegetables, or meat to improve flavor and nutrition. The AI also provides specific ideas for upgrading instant noodles, such as adding eggs, vegetables, meat, or cheese, and asks the human about their preferred way of eating instant noodles, including any favorite flavors or combinations. \\n\"\u001b[39m +\n",
       "  \u001b[32m\"\\n\"\u001b[39m +\n",
       "  \u001b[32m\"Summary: The human craves instant noodles, and the AI recommends enhancing them with additional ingredients like eggs, vegetables, or meat for better taste and nutrition. The AI offers specific upgrade ideas and asks about the human's preferred instant noodle preparation and flavors.\"\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
